{"title":"Data Wrangling","markdown":{"yaml":{"title":"Data Wrangling","author":[{"name":"<font color=#ff6600><b>Biometrics Unit</b></font>","affiliation":"<font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>"}]},"headingText":"[**Introduction**]{style=\"color: #2C6D26;\"}","containsRefs":false,"markdown":"\n\n\nData wrangling is the process of transforming raw data into a more organized and structured format, which facilitates improved insights and better decision-making. Imagine your data as a set of puzzle you need to solve, data wrangling is a tool that will significantly help you to organise the data, making it much easier to solve the data puzzles.\n\nThere are six stages involved in data wrangling, they are highlighted below:\n\n1.  **Data Discovery:** Data discovery is the *process of uncovering and exploring valuable insights* within data. This usually involves collecting data from different sources, transforming and merging it, and employing visualization and analytical methods to reveal patterns, trends, and insights. The aim is to make data more accessible and actionable for decision-making, enabling users to grasp complex information and address specific business questions.\n\n    Data discovery is the process that enables users to visually explore data and apply advanced analytics to uncover patterns, gain insights, answer specific questions, and extract value from business information. It involves integrating and transforming data from multiple sources, analyzing data structures, and using visualization techniques to gain insights and extract valuable information.\n\n2.  **Data Structuring:** Data structures are specialized formats for organizing data on a computer to ensure efficient processing, storage, and retrieval. They provide a systematic way to manage information, making it easier to access and use. A data structure is a *method for organizing and managing data*. It helps in gathering different types of data, whether structured or unstructured, and transforming it into useful and meaningful information. An array is an example of data structure.\n\n3.  **Data Cleaning:** Data cleaning is a vital stage in the data science workflow, focusing on *detecting and rectifying errors, inconsistencies, and inaccuracies in the data to enhance its quality and usability*. This process is crucial because raw data often contains noise, gaps, and inconsistencies that can adversely affect the *accuracy and dependability* of the insights generated from it. Data cleaning involves preparing data for analysis by *correcting or eliminating data that is incorrect, incomplete, irrelevant, duplicated, or poorly formatted*. It involves steps such as *removing unwanted observations, managing structure errors, managing unwanted outliers and handling missing data*.\n\n4.  **Data Enriching:** After transforming your data into a more usable format, evaluate whether you have all the necessary information for your analysis. If not, you can enhance it by incorporating values from additional datasets. This is also a good time to consider adding metadata to your database.\n\n5.  **Data validation:** Once you’ve converted your data into a more usable format, assess if you have all the information required for your analysis. If anything is missing, you can augment it by integrating data from other sources. Additionally, this is an opportune moment to add metadata to your database. Validation *guarantees the quality and reliability of your processed data.* It involves checking for inconsistencies, verifying data integrity, and ensuring the data meets predefined standards. This process helps build confidence in the dataset's accuracy and ensures it is suitable for meaningful analysis.\n\n6.  **Data Publishing:** Data publishing refers to the process of making data available to users, often by sharing or disseminating it through various platforms or channels. This can involve publishing datasets on websites, data repositories, or databases, *ensuring that the data is accessible, usable, and properly documented for others to analyze or utilize.*\n\n    Also, there are three main aspect of data wrangling. These includes:\n\n    1.  Tibbles\n    2.  Data import\n    3.  Tidy data\n\n## [Tibbles]{style=\"color: #002D62;\"}\n\nTibbles are a key feature of the tidyverse, distinguishing it from most other R packages, which typically use standard data frames. You can convert a dataset to tibbles with `as_tibble()`\n\n**Example**\n\n```{r}\nlibrary(tidyverse) #load tidyverse package \nlibrary(agridat)  #load agridat package \ndat <- (australia.soybean) \ndat <-  as_tibble(dat)  #convert dataframe to tibble dat \n```\n\nYou can create tibbles from raw data using `tibble()` as shown below\n\n**Example**\n\n```{r}\ntibble (   x = 1:10,   y = rep(1:5,2),   z = x + y )\n```\n\n**What are the common differences between a tibble and a dataframe**\n\nA tibble is considered a neater format of a data frame and its often used in tidyverse and ggplot2 packages. Tibble has an advanced print function and only shows the first ten rows with all the columns fitted on the screen. The data type is written just below the heading of each column. This does not apply to data frame. Tibble can be used for indexing such as \\$, \\[\\[ \\]\\]. \\$ extracts using name while \\[\\[ \\]\\] extract by name and position.\n\n**Example**\n\n```{r}\nset.seed(234) \ndf <- tibble(   x = runif(5),   y = rnorm(5) )  # Extract by name df$x  \ndf[[\"x\"]]  # Extract by position df[[1]] \n```\n\n## [Data Import]{style=\"color: #002D62;\"}\n\n**Importing a Comma Seperated Version (CSV)**\n\nData import can be done with the `readr` package which is a core `tidyverse` package. This is used for reading data stored in text file spreadsheets into R. Some readr's function are used in turning flat files into dataframe. You can load readr using the code `library(readr)`, this gives you access to functions such as: `read_csv()` for reading comma delimited files, `read_csv2()` for semicolon separated files, `read_table` for white space separated values etc.\n\n```{r}\n#install readr package \ninstall.packages(\"readr\")  # load the package \nlibrary(readr)  #read the csv file into a tibble  \ndata <- read_csv(\"steptoe.morex.pheno.csv\") \ndata\n```\n\n**Importing an Excel Version (XLSL)**\n\nThe readxl library can also be assessed from the readr package and it is used to import excel files. The functions to import excel files are `read_excel()` or `read_xlsx()`. The `read_excel()` auto detect the format while `read_xlsl()`permits more than two sheets in a file.\n\n**Example**\n\n```{r}\n#install the readxl package \n#install.packages(\"readxl\")   #load the readxl package \nlibrary(readxl)  #Read the Excel file into a tibble \ndat <-  read_excel(\"Sugar cane.xlsx\", sheet = \"Sugar cane\") \ndat \n```\n\n## [Tidy Data]{style=\"color: #002D62;\"}\n\nTidy data considers ways to convert your messy dataset into format that are clean and can be easily analysed. The aim of tidyr is to assist in creating tidy data, where:\n\n-   Each variable is represented as a column, and each column corresponds to a variable.\n-   Each observation is represented as a row, and each row corresponds to an observation.\n-   Each value is contained within a cell, with each cell holding a single value.\n\nThe principles of tidy data offer a standardized method for organizing data values within a dataset. The tidy data standard is designed to ease the initial exploration and analysis of data and to streamline the creation of data analysis tools that integrate seamlessly.\n\nVarious functions can be used in the tidyr package, functions such as *pivoting (longer and wider), rectangling, nesting, splitting, replace and drop na* etc.\n\n# [**Examples**]{style=\"color: #2C6D26;\"}\n\n## [Data Frame]{style=\"color: #002D62;\"}\n\n**Let's create a data frame**\n\n```{r}\ntrial01 <- data.frame(   variety = c(\"G01-US234\", \"G05-BT456\", \"Ind01\",\"G11-DR234\", \"Check\"),    yield = c(6323.3, 2515.2, 5611, 7729, 7843.25),   height = c(123.30, 95.2, 113, 89.45, 145.67)   )\n```\n\n**Let's display the data frame**\n\n```{r}\ntrial01  ## display the object in Q2\nView(trial01) ## display the object in Q1 \n#trial01[R,C] \ntrial01[1:5,]\n```\n\n**We can extract the first three rows:**\n\n```{r}\n# object[1:nrows, 1:ncolumns] \ntrial01[1:5, 1:3] \ntrial01[1:3, ] # the three first rows and all columns\n```\n\n```{r}\n# We can extract the first two columns \ntrial01[, 1:2] \n```\n\n```{r}\n# We can extract \"from 3rd to 5th row\" with \"2nd and 3rd column\" \ntrial01[3:5, 2:3]  \ntrial01[,c(1,3)]\n```\n\n```{r}\n# We can list the column names using any of this methods\nnames(trial01) \ncolnames(trial01)\n```\n\n```{r}\n# We can extract specific column from a data frame using column name \ntrial01$  yield1 <- trial01$yield  \ntrial01$yield  \n```\n\n```{r}\n# trial01$Yield. R is case sensitive, yield is different from Yield  # We can find the mean of the extracted column using any of the codes below  \nmean(trial01$yield) \n  \nmean(trial01$yield) \n```\n\n```{r}\n# We can add a column vector using a new column name \ntrial01$flowering <- c(87, 101, 88, 120, 90) \ntrial01$flowering <- c(87,101,88,120,90) \ntrial01 \n\nflowering2 <- c(87,101,88,120,90)  \ntrial01$flowerin2 <- flowering2  \ntrial01\n```\n\n## [The tidyverse package]{style=\"color: #002D62;\"}\n\n```{r}\nlibrary(tidyverse) \ntrial01  # Let's look at the structure of trial01  \nstr(trial01) ## structure of trial01: what's trial01?\n```\n\n```{r}\n# we can convert trial01 to a tibble and save the new created object into trial01.tibble \ntrial01.new <- as_tibble(trial01)  \ntrial01.new # dbl(double) and int(integer) are numeric\n```\n\n## [**Data Import**]{style=\"color: #002D62;\"}\n\n```{r}\n# Read csv file: supply the path to a file and you get the data into R  \nlibrary(readr) \nmydata <- read_csv(\"C:/Users/DOjekere/CGIAR/Fowobaje, Kayode Rapheal (IITA) - Training Materials/2024/R/RMD Training/Example-02.csv\") \nmydata   # If a project/working directory is created and we are working within the project,  \nmydata1 <- read_csv(\"Example-02.csv\") # Tab keyboard\n```\n\n```{r}\n## Read xlsx file \nlibrary(readxl) \niwu <- read_excel(\"C:/Users/DOjekere/CGIAR/Fowobaje, Kayode Rapheal (IITA) - Training Materials/2024/R/RMD Training/Example-03.xlsx\", sheet = \"whitecorn\")  \n## Read Excel file: \nmydata2 <- read_excel(\"Example-03.xlsx\", sheet = \"whitecorn\")\nView(mydata2) \nmydata2\n```\n\n## [Data Transformation]{style=\"color: #002D62;\"}\n\n```{r}\nlibrary(tidyverse)  \nexample02 <- read_csv(\"Example-02.csv\") \nexample02 \n\nnames(example02) \nstr(example02) ## really don't need when you have tibble  # I want to display the number of years\nhead(example02$year) \nunique(example02$year) \nunique(example02$loc) # having the number of locations \n```\n\n### **The pipe \\|\\>**\n\nPipes are a powerful tool for clearly expressing a sequence of multiple operations. Object \\|\\> (object is usually a tibble, a data) Function(argument1, argument2, ...)\n\n### **Filter**\n\nWe can filter the data for 1970\n\n```{r}\nexample02.70 <- example02 |>    \n  filter(year == 1970)\n\nexample02.70\n```\n\nFiltering using the pipe is equivalent to below but not nice\n\n```{r}\nexample02.70.not.nice <- example02[example02$year==1970,] \n\nexample02.70.not.nice \n```\n\nWe can filter the data for one location :\n\n```{r}\nexample02.Lawes <- example02 |>   \n  filter(loc == \"Lawes\") \n\nexample02.Lawes \n```\n\nWe can filter the data with multiple criteria (several arguments)\n\n```{r}\nexample02.Lawes3.2 <- example02 |>    filter(yield > 3.2, loc == \"Lawes\") \n\nexample02.Lawes3.2 <- example02 |>    filter(yield >3.2, loc == \"Brookstead\" | loc == \"Lawes\")\n\nexample02.Lawes3.2 \n```\n\nWhat does the following command do?\n\n```{r}\nexample02 |>    filter(gen == \"G01\" | gen == \"G02\") \n```\n\n### **Arrange**\n\nWe can arrange example02 by yield in ascending order\n\n```{r}\nlibrary(tidyverse) \nlibrary(readxl) \nexample02 <- read_csv(\"Example-02.csv\")  \nexample02 |>    arrange(yield)\n```\n\nWe can arrange example02 by yield in descending order\n\n```{r}\nexample02 |>    arrange(desc(yield))\n```\n\nWe can arrange example02 by year, loc, gen\n\n```{r}\nexample02 |>    arrange(year, loc, gen)  \nexample02 |>    arrange(desc(year), loc, gen) \n```\n\n### **Select**\n\nWhen working with many variables, it can be a good practice to narrow the dataset and consider only few variables for analysis. Let's only consider the location, year, genotype, yield, and height\n\n```{r}\nexample02.short <- example02 |>   \n  select(loc, year, gen, yield, height)  \n\nexample02.short\n```\n\nIf we are interested in moving a particular variable to the first column in the dataframe, select() and everything() can do that. We can also move more than one variable\n\n```{r}\nexample02 |>    select(year, everything())  \nexample02 |>    select(year, loc, gen, everything())\n```\n\n**NOTE:** Select refers to columns: select (yield, loc, gen) -- choose the columns arrange refers to rows: arrange(loc, desc(yield)) -- sort\n\n```{r}\nexample02 |>    select (yield, loc, gen) \n```\n\nThis code will not work because there is no variable named \"desc(yield)\"\n\n```{r}\n#example02 |>         #  select (loc, gen, desc(yield))\n```\n\nBut what we want is:\n\n```         \n1. select the three variables, AND 2. sort the yield in desc order\n```\n\nThis can be done with:\n\n```{r}\nnew <- example02 |>    select (loc, gen, yield) |>    arrange(desc(yield))\n```\n\n### **Add New Variable**\n\nWe can add new columns that are functions of existing columns with `mutate()` which always adds new columns at the end of the data new column\n\n```{r}\nnew1 <- example02.short |>    mutate(yield_kg_ha = yield * 1000)\n```\n\n**Replace an existing column**\n\n```{r}\nnew2 <- example02.short |>    mutate(yield = yield * 1000)\n```\n\n### **Summarize**\n\nWe can be interested having the mean of yield\n\n```{r}\nmean(example02$yield, na.rm = TRUE) \na <- c(2,3,4) \na \nmean(a) \nmean(a, na.rm = TRUE)  \nb <- c(2,3,4,NA) \nb \nmean(b) \nmean(b, na.rm = TRUE)  \nsummary(example02) # summary of the dataframe \n```\n\n**But we prefer using summarize from tidyverse**\n\n`Summarize()` collapses a data frame to a single or few row(s)\n\n```{r}\nexample02 |>    summarize(yield_mean = mean(yield, na.rm=TRUE))\n```\n\n**Summarize by group**\n\n```{r}\nunique(example02$loc) \n\nexample02 |>   group_by(loc) |>   summarise(yield_loc = mean(yield, na.rm = TRUE))\n\nexample02 |>   group_by(loc, year) |>   summarise(yield_loc = mean(yield, na.rm = TRUE)) \n\nexample02 |>   group_by(gen) |>   summarise(yield = mean(yield, na.rm = TRUE)) |>    arrange(desc(yield))  \n\nexample02 |>   group_by(gen, loc) |>   summarise(yield = mean(yield, na.rm = TRUE)) |>    arrange(desc(yield))\n```\n\n### **Missing values**\n\n```{r}\nmissing_dat <- read_csv(\"Example-02-missing.csv\") \n\nmean(missing_dat$yield, na.rm = TRUE)\n```\n\n**How to get the missing data if any**\n\n```{r}\nexample02.missing <- read_csv(\"Example-02-missing.csv\")\n\nmissing_dat |>    group_by(loc) |>    \n  summarize(Nmissing=sum(is.na(yield))) \n```\n\nSelect the obs with a missing yield\n\n```{r}\nmissing_dat |>    filter(is.na(yield))\n```\n\nThe total number of obs is 464\n\n```{r}\nexample02.missing |>    filter(!is.na(yield)) \n```\n\n464 obs = 461 valid + 3 missing\n\n```{r}\nhead(is.na(example02.missing$yield)) \nsum(is.na(example02.missing$yield)) \n```\n\n### **Count**\n\nCounting the number of observations\n\n```{r}\nexample02 |>   group_by(loc) |>   summarise(new4 = n())\n```\n\n### **Factors**\n\nThe function as.factor() convert a variable to a factor\n\n```{r}\nexample02$env <- as.factor(example02$env)\nexample02$loc <- as.factor(example02$loc) \nexample02$gen <- as.factor(example02$gen) \n```\n\nThis is equivalent to the code below using mutate() and the pipe \\|\\>\n\n```{r}\nexample02 <- example02 |>   mutate(     env=factor(env),     \n                                        loc=factor(loc),     gen=factor(gen)   ) \n\n\nexample02 |>   mutate(across(c(env, loc, gen)))\n```\n\nTo display the levels of a factor\n\n```{r}\nlevels(example02$loc)\n```\n\nTo get the number of levels of a factor\n\n```{r}\nnlevels(example02$env)\n```\n\n# [**Pivoting**]{style=\"color: #2C6D26;\"}\n\nData management is an important task during data analysis because most times, datasets do not come in the required shape for analysis and result presentation. Hence, the need for conversion of dataset tables from wide to long format, or vice versa. It is important to understand data frame intuition where variables are in columns, observations are in rows, and values are in the cell.\n\n![](images/tibble.png)\n\nThe `pivot_wider()` or `pivot_longer()` functions in R **tidyverse** package help reorganize or reshape data values into the needed layout.\n\n![](images/Pivot.jpg) <br><br>\n\n## [**Pivot Longer**]{style=\"color:#002D62;\"}\n\nA common problem is a dataset where some of the column names are not names of variables, but values of a variable. The function `pivot_longer()` transform the dataset in wide format to longer.\n\nBelow is the basic R syntax needed to transform data from a wide format to a long format:\n\n```{r }\n#|eval = FALSE\n#pivot_longer(data, cols, names_to = \"xxx\", values_to = \"yyy\") #<<\n```\n\n-   `data`: a data frame to pivot longer\n-   `cols`: columns to pivot into long format\n-   `names_to`: a character specifying the name of the selected columns to pivot\n-   `values_to`: a character specifying the name of the cell values in the pivoted columns.\n\n## [**Example**]{style=\"color: #002D62;\"}\n\nTo illustrate how this function works, let’s import the Australia Soybean 1970 dataset.\n\n```{r }\n#|echo=TRUE\n#|results=\"tiny\"\n#library(tidyverse) \ndat <- read_csv(\"australia.soybean1970.csv\") \n```\n\nWe have a data frame with 7 variables (env, loc, year, gen, yield, height, and lodging) and 232 observations. The data frame is stored under an object named **dat**\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat\n```\n\nAs you can see, the dataset is already in wide format as seen from the previous slide. To transform the dataset into a long format, we use the function `pivot_longer`\n\n```{r }\n#|echo=TRUE\n#|tidy=FALSE\ndat_longer <- dat |>   pivot_longer(yield:lodging, names_to = \"trait\", values_to = \"values\") \n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_longer\n```\n\n## [**Pivot Wider**]{style=\"color: #2C6D26;\"}\n\nThe function `pivot_wider()` is the opposite of the `pivot_longer()` function. It transforms the dataset from long format to wider. Below is the basic R syntax needed to transform data from a wide format to a long format:\n\n```{r}\n#|echo=TRUE\n#pivot_wider(data, names_from = \"xxx\", values_from = \"yyy\") #<<\n```\n\n-   `data`: a data frame to pivot wider\n-   `names_from`: the name of the output column\n-   `values_from`: the name of the column to get the cell values from\n\n## [**Example**]{style=\"color: #002D62;\"}\n\nTo transform the dataset into a wide format, we use the function `pivot_wider()`\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\nlibrary(tidyverse) \ndat <- read_csv(\"Longer.csv\") \n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat\n```\n\n```{r }\n#|echo=TRUE\n#|tidy=FALSE\ndat_wider <- dat |>   pivot_wider(names_from = \"trait\", values_from = \"values\")\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_wider\n```\n\n# [**Combining Tables**]{style=\"color: #2C6D26;\"}\n\nSo far we have seen how tidy data can be reshaped. However, there are occasions when dataset comes from different data sources and we need to combine them together before we proceed further to analysis or result presentation. The `dplyr` in R **tidyverse** package offers different mutating join functions to combine datasets together. A mutating join function allows you to combine variables from two tables by matching observations by key variable(s), then copy variables from one table to another.\n\nThere are four common mutating joins: `left_join`, `right_join`, `inner_join`, and `full_join`. They all have the same arguments but return different tables, *df1* and *df2* are a pair of data frames to join, and *by* is a unique character vector variable(s) to join the data frames by.\n\n## [**Left Join**]{style=\"color: #002D62;\"}\n\n`left_join(df1, df2, by)`\n\n```{r} #join matching values from df2 to df1}\n```\n\n![](images/left1.jpg){width=\"30%\"}\n\n![](images/left2.jpg){width=\"30%\"}\n\nA left join in R is a kind of database join that joins two data frames together by their columns using a shared key. Only the matching rows from the right data frame are included in the result of a left join, which contains all of the rows from the left data frame. NA values are entered for each column in the corresponding data frame if there is no match.\\\n\\\n**Example** To demonstrate how these mutating joins work, let’s import the pair of data frames needed.\n\n```{r }\n#|echo=TRUE\n\nlibrary(readxl) \ndat1 <- read_excel(\"df.combine.xlsx\", sheet=\"df1\") \ndat2 <- read_excel(\"df.combine.xlsx\", sheet=\"df2\")\n```\n\n**dat1** has 15 observations with five variables:gen, yield, height, size, and protein.\n\n**dat2** has 15 observations with two variables:gen, oil.\n\nDisplay the observations in dat1\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat1\n```\n\nDisplay the observations in dat2\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat2\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Left join \ndf_left <- left_join(dat1, dat2)   \ndf_left\n```\n\n-   The code performs a left join on `dat1` and `dat2`, resulting in a new data frame `df_left` that contains all rows from the left data frame (`dat1`) along with matching rows from `dat2`. Rows in `dat1` without a corresponding match in `dat2` will have `NA` in their resulting columns for data from `dat2`.\n\n## [**Right Join**]{style=\"color: #002D62;\"}\n\n`right_join(df1, df2, by)`\n\n```{r}\n#join matching values from df2 to df1 \n```\n\n![](images/right1.jpg){width=\"30%\"}\n\n![](images/right2.jpg){width=\"30%\"}\n\nA right join is a type of database join that combines two data frames based on a common key, similar to a left join but with a focus on retaining all the rows from the right data frame. When performing a right join, all rows from the right data frame are included in the result, and only the matching rows from the left data frame are included. If there is no match, the corresponding columns of the left data frame will be filled with `NA` values\n\n**Example**\n\nContinuing with the previous data,\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Right join \ndf_right <- right_join(dat1, dat2)   \ndf_right\n```\n\nThe right join operation retains all rows from the right data frame (`dat2`) and only those rows from the left data frame (`dat1`) that match based on the specified keys. If there are entries in `dat2` without corresponding matches in `dat1`, the output will show `NA` in place of those unmatched entries from `dat1`\n\n## [**Inner Join**]{style=\"color: #002D62;\"}\n\n`inner_join(df1, df2, by)`\n\n```{r}\n#join values from df2 to df1 and retain only matching rows\n```\n\n![](images/inner1.jpg){width=\"30%\"}\n\n![](images/inner2.jpg){width=\"30%\"}\n\nAn inner join is a type of database join that combines two data frames (or tables) based on a common key or keys, returning only those rows where there is a match in both data frames. In other words, an inner join retrieves the intersection of the two dataset\n\n**Example**\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Inner join \ndf_inner <- inner_join(dat1, dat2)   \ndf_inner\n```\n\nThe resulting data frame (`df_inner`) contains only those rows where there are matching values in the `id` column of both `dat1` and `dat2`\n\n## [**Full join**]{style=\"color: #002D62;\"}\n\n`full_join(df1, df2, by)`\n\n```{r} #join values from df2 to df1 and retain all rows, all values}\n```\n\n![](images/full1.jpg){width=\"30%\"}\n\n![](images/full2.jpg){width=\"30%\"}\n\nA full join (or full outer join) is a type of database join that combines the results of both left and right joins. This means that a full join returns all the rows from both data frames (or tables), regardless of whether there is a match between them. If a row in one data frame does not have a corresponding match in the other, the result will contain `NA` (or missing values) for the columns of the unmatched row from the other data frame.\n\n**Example**\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Full join \ndf_full <- full_join(dat1, dat2)   \ndf_full\n```\n\nThe code `df_full <- full_join(dat1, dat2)` effectively creates a new data frame that combines data from `dat1` and `dat2`, ensuring that all records are retained, either matched or unmatched. This type of join is particularly useful in exploratory data analysis and situations where preserving all relevant data is critical for further analysis and interpretation.\n\n# [**Creating Groups**]{style=\"color: #2C6D26;\"}\n\nData wrangling in R sometimes requires modification or creating a new variable based on certain possible conditions during data analysis.\n\nIt is possible to create new variables with the mutate() function in the tidyverse package.\n\nThe `case_when()` function allows you to vectorize multiple `if_else` statements, i.e. you test condition-1, and then output output-value-1 if the condition-1 is true, then test condition-2, and output output-value-2 if condition-2 is true, the logical statements continue until you specify a value to output if none of the conditions were true.\n\nHowever, if we are interested in creating a new variable within a dataframe based on certain conditions with some `if-elif-else` style logic, then the case_when() function is used with the `mutate()` function, both are in the **tidyverse** package.\n\nTo illustrate the description in the previous slide, let's consider the image below\n\n![](images/case_when.jpg)\n\nThe `TRUE~` is equivalent to the `‘else’` in the `‘if-else’` statement.\n\nIt is important to note that the conditions are evaluated in order, therefore one must proceed from the most specific to the most general condition.\n\nLet’s demonstrate how `case_when` works with these examples using the Australia Soybean 1970 dataset.\n\nWe are going to create four lodging categories such as \\>=1 = 'No Lodging', \\>=1.5 = 'Mild Lodging', \\>=2.5 = 'Moderate Lodging', and \\>=3.5 = 'Heavy Lodging'.\n\n```{r}\n#|echo=TRUE\n\ndat <- read_csv(\"australia.soybean1970.csv\") \ndat\n```\n\n```{r }\n#|echo=TRUE\n#|tidy=FALSE\n\ndat_new <- dat |>      \t\tmutate(         \t\t\tlodging_grp = case_when(                                       lodging >= 3.5 ~ \"Heavy Lodging\",                                 \t\t  lodging >= 2.5 ~ \"Moderate Lodging\",                                \t\t  \tlodging >= 1.5 ~ \"Mild Lodging\",                                 \t\t  lodging >= 1 ~ \"No Lodging\",                                 \t\t \t\t       TRUE ~ \"NA\")  \t\t\t ) \n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_new \n```\n\nAlso, we may be interested in creating a new variable from the existing categorical variable.\n\nLet’s use the new data set `dat_new` to demonstrate this process using `mutate` and `case_when` functions and introduce the `IN` operator `%in%` i.e. We create two lodging categories such that `'No Lodging'` and `'Mild Lodging'` will be `\"No Lodging\"`, and `'Moderate Lodging'` and `'Heavy Lodging'` will be `\"Lodging\"`.\n\n```{r}\n#|echo=TRUE\n#|tidy=FALSE\ndat_new <- dat_new |>           mutate(           lodging_grp2 = case_when(           lodging_grp %in% c(\"Heavy Lodging\",\"Moderate Lodging\")  ~ \"Lodging\",           lodging_grp %in% c(\"No Lodging\", \"Mild Lodging\") ~ \"No Lodging\",                                                     TRUE   ~ \"NA\")   \t\t)\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_new \n```\n\n# [**Strings**]{style=\"color: #2C6D26;\"}\n\nAs we all know that data comes in different formats, numeric or non-numeric (text/string) data format. Data wrangling of non-numeric data sometimes requires splitting of the cell into multiple individual cells or combining multiple cells into a single cell before analysis.\n\nThere are some functions in the tidyverse package used for this purpose such as `unite()`, `separate()`, and `str_sub()`.\n\n-   `unite()`: collapse cells across several columns into a single column.\n\n-   `separate()`: separate each cell in a column into several columns.\n\n-   `str_sub()`: extract a substring from a character vector.\n\nLet’s use a fictitious data set called **BadData** to demonstrate how these functions work.\n\nThe data set has seven (7) variables: Gen: A combination of location, genotype, and replication, Year: Year of trials, Traits: Measured traits (Trait1 – Trait5)\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat <- read_csv(\"BadData.csv\") \ndat\n```\n\nThe first task will be to create separate variables for location, genotype, and replication from the Gen variable.\n\n```{r}\n#|echo=TRUE\n#|tidy=FALSE\ndat1 <- dat |>    separate(Gen, sep = \"-\", into = c(\"LocGen\", \"Rep\")) |>    mutate(           Location = str_sub(LocGen, 1, 2),           Gen = str_sub(LocGen, 3, 5)  \t ) |>    select(Location, Gen, Rep, Year, Trait1, Trait2, Trait3, Trait4, Trait5)\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat1\n```\n\nAlso, we may be interested in creating a new variable which will be a combination of at least two variables. Suppose we want to create a variable called environment `(Env)` using the data set above by combining the Location and Year together.\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat1 <- dat1 |>          unite(Location, Year, col = \"Env\", sep = \"-\") \ndat1\n```\n\n## [**Exercise**]{style=\"color: #2C6D26;\"}\n\n1.  Import Example-02.csv to R and save it to an object named example02 Display the example02 object filter the data by considering: locations Nambour and RedlandBay genotypes G01, G57, and G58, location Brookstead for the year 1970 location Lawes yield between 2 and 3 inclusive, oil greater than 22\n\n2.  Import **Example-02.csv** to R and save to an object named **example02** Create a new variable called `ENV` by combining the first three letters in `loc` and the last two digit in `year`. Categorize the `yield` values of at least 3 as `\"High\"` and other values as `\"Low\"` into a new variable called `yield_grp`. Select `ENV`, `gen`, `yield`, `yield_grp`, `height`, and `oil` and transform the dataset using appropriate variables as `traits`.\n","srcMarkdownNoYaml":"\n\n# [**Introduction**]{style=\"color: #2C6D26;\"}\n\nData wrangling is the process of transforming raw data into a more organized and structured format, which facilitates improved insights and better decision-making. Imagine your data as a set of puzzle you need to solve, data wrangling is a tool that will significantly help you to organise the data, making it much easier to solve the data puzzles.\n\nThere are six stages involved in data wrangling, they are highlighted below:\n\n1.  **Data Discovery:** Data discovery is the *process of uncovering and exploring valuable insights* within data. This usually involves collecting data from different sources, transforming and merging it, and employing visualization and analytical methods to reveal patterns, trends, and insights. The aim is to make data more accessible and actionable for decision-making, enabling users to grasp complex information and address specific business questions.\n\n    Data discovery is the process that enables users to visually explore data and apply advanced analytics to uncover patterns, gain insights, answer specific questions, and extract value from business information. It involves integrating and transforming data from multiple sources, analyzing data structures, and using visualization techniques to gain insights and extract valuable information.\n\n2.  **Data Structuring:** Data structures are specialized formats for organizing data on a computer to ensure efficient processing, storage, and retrieval. They provide a systematic way to manage information, making it easier to access and use. A data structure is a *method for organizing and managing data*. It helps in gathering different types of data, whether structured or unstructured, and transforming it into useful and meaningful information. An array is an example of data structure.\n\n3.  **Data Cleaning:** Data cleaning is a vital stage in the data science workflow, focusing on *detecting and rectifying errors, inconsistencies, and inaccuracies in the data to enhance its quality and usability*. This process is crucial because raw data often contains noise, gaps, and inconsistencies that can adversely affect the *accuracy and dependability* of the insights generated from it. Data cleaning involves preparing data for analysis by *correcting or eliminating data that is incorrect, incomplete, irrelevant, duplicated, or poorly formatted*. It involves steps such as *removing unwanted observations, managing structure errors, managing unwanted outliers and handling missing data*.\n\n4.  **Data Enriching:** After transforming your data into a more usable format, evaluate whether you have all the necessary information for your analysis. If not, you can enhance it by incorporating values from additional datasets. This is also a good time to consider adding metadata to your database.\n\n5.  **Data validation:** Once you’ve converted your data into a more usable format, assess if you have all the information required for your analysis. If anything is missing, you can augment it by integrating data from other sources. Additionally, this is an opportune moment to add metadata to your database. Validation *guarantees the quality and reliability of your processed data.* It involves checking for inconsistencies, verifying data integrity, and ensuring the data meets predefined standards. This process helps build confidence in the dataset's accuracy and ensures it is suitable for meaningful analysis.\n\n6.  **Data Publishing:** Data publishing refers to the process of making data available to users, often by sharing or disseminating it through various platforms or channels. This can involve publishing datasets on websites, data repositories, or databases, *ensuring that the data is accessible, usable, and properly documented for others to analyze or utilize.*\n\n    Also, there are three main aspect of data wrangling. These includes:\n\n    1.  Tibbles\n    2.  Data import\n    3.  Tidy data\n\n## [Tibbles]{style=\"color: #002D62;\"}\n\nTibbles are a key feature of the tidyverse, distinguishing it from most other R packages, which typically use standard data frames. You can convert a dataset to tibbles with `as_tibble()`\n\n**Example**\n\n```{r}\nlibrary(tidyverse) #load tidyverse package \nlibrary(agridat)  #load agridat package \ndat <- (australia.soybean) \ndat <-  as_tibble(dat)  #convert dataframe to tibble dat \n```\n\nYou can create tibbles from raw data using `tibble()` as shown below\n\n**Example**\n\n```{r}\ntibble (   x = 1:10,   y = rep(1:5,2),   z = x + y )\n```\n\n**What are the common differences between a tibble and a dataframe**\n\nA tibble is considered a neater format of a data frame and its often used in tidyverse and ggplot2 packages. Tibble has an advanced print function and only shows the first ten rows with all the columns fitted on the screen. The data type is written just below the heading of each column. This does not apply to data frame. Tibble can be used for indexing such as \\$, \\[\\[ \\]\\]. \\$ extracts using name while \\[\\[ \\]\\] extract by name and position.\n\n**Example**\n\n```{r}\nset.seed(234) \ndf <- tibble(   x = runif(5),   y = rnorm(5) )  # Extract by name df$x  \ndf[[\"x\"]]  # Extract by position df[[1]] \n```\n\n## [Data Import]{style=\"color: #002D62;\"}\n\n**Importing a Comma Seperated Version (CSV)**\n\nData import can be done with the `readr` package which is a core `tidyverse` package. This is used for reading data stored in text file spreadsheets into R. Some readr's function are used in turning flat files into dataframe. You can load readr using the code `library(readr)`, this gives you access to functions such as: `read_csv()` for reading comma delimited files, `read_csv2()` for semicolon separated files, `read_table` for white space separated values etc.\n\n```{r}\n#install readr package \ninstall.packages(\"readr\")  # load the package \nlibrary(readr)  #read the csv file into a tibble  \ndata <- read_csv(\"steptoe.morex.pheno.csv\") \ndata\n```\n\n**Importing an Excel Version (XLSL)**\n\nThe readxl library can also be assessed from the readr package and it is used to import excel files. The functions to import excel files are `read_excel()` or `read_xlsx()`. The `read_excel()` auto detect the format while `read_xlsl()`permits more than two sheets in a file.\n\n**Example**\n\n```{r}\n#install the readxl package \n#install.packages(\"readxl\")   #load the readxl package \nlibrary(readxl)  #Read the Excel file into a tibble \ndat <-  read_excel(\"Sugar cane.xlsx\", sheet = \"Sugar cane\") \ndat \n```\n\n## [Tidy Data]{style=\"color: #002D62;\"}\n\nTidy data considers ways to convert your messy dataset into format that are clean and can be easily analysed. The aim of tidyr is to assist in creating tidy data, where:\n\n-   Each variable is represented as a column, and each column corresponds to a variable.\n-   Each observation is represented as a row, and each row corresponds to an observation.\n-   Each value is contained within a cell, with each cell holding a single value.\n\nThe principles of tidy data offer a standardized method for organizing data values within a dataset. The tidy data standard is designed to ease the initial exploration and analysis of data and to streamline the creation of data analysis tools that integrate seamlessly.\n\nVarious functions can be used in the tidyr package, functions such as *pivoting (longer and wider), rectangling, nesting, splitting, replace and drop na* etc.\n\n# [**Examples**]{style=\"color: #2C6D26;\"}\n\n## [Data Frame]{style=\"color: #002D62;\"}\n\n**Let's create a data frame**\n\n```{r}\ntrial01 <- data.frame(   variety = c(\"G01-US234\", \"G05-BT456\", \"Ind01\",\"G11-DR234\", \"Check\"),    yield = c(6323.3, 2515.2, 5611, 7729, 7843.25),   height = c(123.30, 95.2, 113, 89.45, 145.67)   )\n```\n\n**Let's display the data frame**\n\n```{r}\ntrial01  ## display the object in Q2\nView(trial01) ## display the object in Q1 \n#trial01[R,C] \ntrial01[1:5,]\n```\n\n**We can extract the first three rows:**\n\n```{r}\n# object[1:nrows, 1:ncolumns] \ntrial01[1:5, 1:3] \ntrial01[1:3, ] # the three first rows and all columns\n```\n\n```{r}\n# We can extract the first two columns \ntrial01[, 1:2] \n```\n\n```{r}\n# We can extract \"from 3rd to 5th row\" with \"2nd and 3rd column\" \ntrial01[3:5, 2:3]  \ntrial01[,c(1,3)]\n```\n\n```{r}\n# We can list the column names using any of this methods\nnames(trial01) \ncolnames(trial01)\n```\n\n```{r}\n# We can extract specific column from a data frame using column name \ntrial01$  yield1 <- trial01$yield  \ntrial01$yield  \n```\n\n```{r}\n# trial01$Yield. R is case sensitive, yield is different from Yield  # We can find the mean of the extracted column using any of the codes below  \nmean(trial01$yield) \n  \nmean(trial01$yield) \n```\n\n```{r}\n# We can add a column vector using a new column name \ntrial01$flowering <- c(87, 101, 88, 120, 90) \ntrial01$flowering <- c(87,101,88,120,90) \ntrial01 \n\nflowering2 <- c(87,101,88,120,90)  \ntrial01$flowerin2 <- flowering2  \ntrial01\n```\n\n## [The tidyverse package]{style=\"color: #002D62;\"}\n\n```{r}\nlibrary(tidyverse) \ntrial01  # Let's look at the structure of trial01  \nstr(trial01) ## structure of trial01: what's trial01?\n```\n\n```{r}\n# we can convert trial01 to a tibble and save the new created object into trial01.tibble \ntrial01.new <- as_tibble(trial01)  \ntrial01.new # dbl(double) and int(integer) are numeric\n```\n\n## [**Data Import**]{style=\"color: #002D62;\"}\n\n```{r}\n# Read csv file: supply the path to a file and you get the data into R  \nlibrary(readr) \nmydata <- read_csv(\"C:/Users/DOjekere/CGIAR/Fowobaje, Kayode Rapheal (IITA) - Training Materials/2024/R/RMD Training/Example-02.csv\") \nmydata   # If a project/working directory is created and we are working within the project,  \nmydata1 <- read_csv(\"Example-02.csv\") # Tab keyboard\n```\n\n```{r}\n## Read xlsx file \nlibrary(readxl) \niwu <- read_excel(\"C:/Users/DOjekere/CGIAR/Fowobaje, Kayode Rapheal (IITA) - Training Materials/2024/R/RMD Training/Example-03.xlsx\", sheet = \"whitecorn\")  \n## Read Excel file: \nmydata2 <- read_excel(\"Example-03.xlsx\", sheet = \"whitecorn\")\nView(mydata2) \nmydata2\n```\n\n## [Data Transformation]{style=\"color: #002D62;\"}\n\n```{r}\nlibrary(tidyverse)  \nexample02 <- read_csv(\"Example-02.csv\") \nexample02 \n\nnames(example02) \nstr(example02) ## really don't need when you have tibble  # I want to display the number of years\nhead(example02$year) \nunique(example02$year) \nunique(example02$loc) # having the number of locations \n```\n\n### **The pipe \\|\\>**\n\nPipes are a powerful tool for clearly expressing a sequence of multiple operations. Object \\|\\> (object is usually a tibble, a data) Function(argument1, argument2, ...)\n\n### **Filter**\n\nWe can filter the data for 1970\n\n```{r}\nexample02.70 <- example02 |>    \n  filter(year == 1970)\n\nexample02.70\n```\n\nFiltering using the pipe is equivalent to below but not nice\n\n```{r}\nexample02.70.not.nice <- example02[example02$year==1970,] \n\nexample02.70.not.nice \n```\n\nWe can filter the data for one location :\n\n```{r}\nexample02.Lawes <- example02 |>   \n  filter(loc == \"Lawes\") \n\nexample02.Lawes \n```\n\nWe can filter the data with multiple criteria (several arguments)\n\n```{r}\nexample02.Lawes3.2 <- example02 |>    filter(yield > 3.2, loc == \"Lawes\") \n\nexample02.Lawes3.2 <- example02 |>    filter(yield >3.2, loc == \"Brookstead\" | loc == \"Lawes\")\n\nexample02.Lawes3.2 \n```\n\nWhat does the following command do?\n\n```{r}\nexample02 |>    filter(gen == \"G01\" | gen == \"G02\") \n```\n\n### **Arrange**\n\nWe can arrange example02 by yield in ascending order\n\n```{r}\nlibrary(tidyverse) \nlibrary(readxl) \nexample02 <- read_csv(\"Example-02.csv\")  \nexample02 |>    arrange(yield)\n```\n\nWe can arrange example02 by yield in descending order\n\n```{r}\nexample02 |>    arrange(desc(yield))\n```\n\nWe can arrange example02 by year, loc, gen\n\n```{r}\nexample02 |>    arrange(year, loc, gen)  \nexample02 |>    arrange(desc(year), loc, gen) \n```\n\n### **Select**\n\nWhen working with many variables, it can be a good practice to narrow the dataset and consider only few variables for analysis. Let's only consider the location, year, genotype, yield, and height\n\n```{r}\nexample02.short <- example02 |>   \n  select(loc, year, gen, yield, height)  \n\nexample02.short\n```\n\nIf we are interested in moving a particular variable to the first column in the dataframe, select() and everything() can do that. We can also move more than one variable\n\n```{r}\nexample02 |>    select(year, everything())  \nexample02 |>    select(year, loc, gen, everything())\n```\n\n**NOTE:** Select refers to columns: select (yield, loc, gen) -- choose the columns arrange refers to rows: arrange(loc, desc(yield)) -- sort\n\n```{r}\nexample02 |>    select (yield, loc, gen) \n```\n\nThis code will not work because there is no variable named \"desc(yield)\"\n\n```{r}\n#example02 |>         #  select (loc, gen, desc(yield))\n```\n\nBut what we want is:\n\n```         \n1. select the three variables, AND 2. sort the yield in desc order\n```\n\nThis can be done with:\n\n```{r}\nnew <- example02 |>    select (loc, gen, yield) |>    arrange(desc(yield))\n```\n\n### **Add New Variable**\n\nWe can add new columns that are functions of existing columns with `mutate()` which always adds new columns at the end of the data new column\n\n```{r}\nnew1 <- example02.short |>    mutate(yield_kg_ha = yield * 1000)\n```\n\n**Replace an existing column**\n\n```{r}\nnew2 <- example02.short |>    mutate(yield = yield * 1000)\n```\n\n### **Summarize**\n\nWe can be interested having the mean of yield\n\n```{r}\nmean(example02$yield, na.rm = TRUE) \na <- c(2,3,4) \na \nmean(a) \nmean(a, na.rm = TRUE)  \nb <- c(2,3,4,NA) \nb \nmean(b) \nmean(b, na.rm = TRUE)  \nsummary(example02) # summary of the dataframe \n```\n\n**But we prefer using summarize from tidyverse**\n\n`Summarize()` collapses a data frame to a single or few row(s)\n\n```{r}\nexample02 |>    summarize(yield_mean = mean(yield, na.rm=TRUE))\n```\n\n**Summarize by group**\n\n```{r}\nunique(example02$loc) \n\nexample02 |>   group_by(loc) |>   summarise(yield_loc = mean(yield, na.rm = TRUE))\n\nexample02 |>   group_by(loc, year) |>   summarise(yield_loc = mean(yield, na.rm = TRUE)) \n\nexample02 |>   group_by(gen) |>   summarise(yield = mean(yield, na.rm = TRUE)) |>    arrange(desc(yield))  \n\nexample02 |>   group_by(gen, loc) |>   summarise(yield = mean(yield, na.rm = TRUE)) |>    arrange(desc(yield))\n```\n\n### **Missing values**\n\n```{r}\nmissing_dat <- read_csv(\"Example-02-missing.csv\") \n\nmean(missing_dat$yield, na.rm = TRUE)\n```\n\n**How to get the missing data if any**\n\n```{r}\nexample02.missing <- read_csv(\"Example-02-missing.csv\")\n\nmissing_dat |>    group_by(loc) |>    \n  summarize(Nmissing=sum(is.na(yield))) \n```\n\nSelect the obs with a missing yield\n\n```{r}\nmissing_dat |>    filter(is.na(yield))\n```\n\nThe total number of obs is 464\n\n```{r}\nexample02.missing |>    filter(!is.na(yield)) \n```\n\n464 obs = 461 valid + 3 missing\n\n```{r}\nhead(is.na(example02.missing$yield)) \nsum(is.na(example02.missing$yield)) \n```\n\n### **Count**\n\nCounting the number of observations\n\n```{r}\nexample02 |>   group_by(loc) |>   summarise(new4 = n())\n```\n\n### **Factors**\n\nThe function as.factor() convert a variable to a factor\n\n```{r}\nexample02$env <- as.factor(example02$env)\nexample02$loc <- as.factor(example02$loc) \nexample02$gen <- as.factor(example02$gen) \n```\n\nThis is equivalent to the code below using mutate() and the pipe \\|\\>\n\n```{r}\nexample02 <- example02 |>   mutate(     env=factor(env),     \n                                        loc=factor(loc),     gen=factor(gen)   ) \n\n\nexample02 |>   mutate(across(c(env, loc, gen)))\n```\n\nTo display the levels of a factor\n\n```{r}\nlevels(example02$loc)\n```\n\nTo get the number of levels of a factor\n\n```{r}\nnlevels(example02$env)\n```\n\n# [**Pivoting**]{style=\"color: #2C6D26;\"}\n\nData management is an important task during data analysis because most times, datasets do not come in the required shape for analysis and result presentation. Hence, the need for conversion of dataset tables from wide to long format, or vice versa. It is important to understand data frame intuition where variables are in columns, observations are in rows, and values are in the cell.\n\n![](images/tibble.png)\n\nThe `pivot_wider()` or `pivot_longer()` functions in R **tidyverse** package help reorganize or reshape data values into the needed layout.\n\n![](images/Pivot.jpg) <br><br>\n\n## [**Pivot Longer**]{style=\"color:#002D62;\"}\n\nA common problem is a dataset where some of the column names are not names of variables, but values of a variable. The function `pivot_longer()` transform the dataset in wide format to longer.\n\nBelow is the basic R syntax needed to transform data from a wide format to a long format:\n\n```{r }\n#|eval = FALSE\n#pivot_longer(data, cols, names_to = \"xxx\", values_to = \"yyy\") #<<\n```\n\n-   `data`: a data frame to pivot longer\n-   `cols`: columns to pivot into long format\n-   `names_to`: a character specifying the name of the selected columns to pivot\n-   `values_to`: a character specifying the name of the cell values in the pivoted columns.\n\n## [**Example**]{style=\"color: #002D62;\"}\n\nTo illustrate how this function works, let’s import the Australia Soybean 1970 dataset.\n\n```{r }\n#|echo=TRUE\n#|results=\"tiny\"\n#library(tidyverse) \ndat <- read_csv(\"australia.soybean1970.csv\") \n```\n\nWe have a data frame with 7 variables (env, loc, year, gen, yield, height, and lodging) and 232 observations. The data frame is stored under an object named **dat**\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat\n```\n\nAs you can see, the dataset is already in wide format as seen from the previous slide. To transform the dataset into a long format, we use the function `pivot_longer`\n\n```{r }\n#|echo=TRUE\n#|tidy=FALSE\ndat_longer <- dat |>   pivot_longer(yield:lodging, names_to = \"trait\", values_to = \"values\") \n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_longer\n```\n\n## [**Pivot Wider**]{style=\"color: #2C6D26;\"}\n\nThe function `pivot_wider()` is the opposite of the `pivot_longer()` function. It transforms the dataset from long format to wider. Below is the basic R syntax needed to transform data from a wide format to a long format:\n\n```{r}\n#|echo=TRUE\n#pivot_wider(data, names_from = \"xxx\", values_from = \"yyy\") #<<\n```\n\n-   `data`: a data frame to pivot wider\n-   `names_from`: the name of the output column\n-   `values_from`: the name of the column to get the cell values from\n\n## [**Example**]{style=\"color: #002D62;\"}\n\nTo transform the dataset into a wide format, we use the function `pivot_wider()`\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\nlibrary(tidyverse) \ndat <- read_csv(\"Longer.csv\") \n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat\n```\n\n```{r }\n#|echo=TRUE\n#|tidy=FALSE\ndat_wider <- dat |>   pivot_wider(names_from = \"trait\", values_from = \"values\")\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_wider\n```\n\n# [**Combining Tables**]{style=\"color: #2C6D26;\"}\n\nSo far we have seen how tidy data can be reshaped. However, there are occasions when dataset comes from different data sources and we need to combine them together before we proceed further to analysis or result presentation. The `dplyr` in R **tidyverse** package offers different mutating join functions to combine datasets together. A mutating join function allows you to combine variables from two tables by matching observations by key variable(s), then copy variables from one table to another.\n\nThere are four common mutating joins: `left_join`, `right_join`, `inner_join`, and `full_join`. They all have the same arguments but return different tables, *df1* and *df2* are a pair of data frames to join, and *by* is a unique character vector variable(s) to join the data frames by.\n\n## [**Left Join**]{style=\"color: #002D62;\"}\n\n`left_join(df1, df2, by)`\n\n```{r} #join matching values from df2 to df1}\n```\n\n![](images/left1.jpg){width=\"30%\"}\n\n![](images/left2.jpg){width=\"30%\"}\n\nA left join in R is a kind of database join that joins two data frames together by their columns using a shared key. Only the matching rows from the right data frame are included in the result of a left join, which contains all of the rows from the left data frame. NA values are entered for each column in the corresponding data frame if there is no match.\\\n\\\n**Example** To demonstrate how these mutating joins work, let’s import the pair of data frames needed.\n\n```{r }\n#|echo=TRUE\n\nlibrary(readxl) \ndat1 <- read_excel(\"df.combine.xlsx\", sheet=\"df1\") \ndat2 <- read_excel(\"df.combine.xlsx\", sheet=\"df2\")\n```\n\n**dat1** has 15 observations with five variables:gen, yield, height, size, and protein.\n\n**dat2** has 15 observations with two variables:gen, oil.\n\nDisplay the observations in dat1\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat1\n```\n\nDisplay the observations in dat2\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat2\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Left join \ndf_left <- left_join(dat1, dat2)   \ndf_left\n```\n\n-   The code performs a left join on `dat1` and `dat2`, resulting in a new data frame `df_left` that contains all rows from the left data frame (`dat1`) along with matching rows from `dat2`. Rows in `dat1` without a corresponding match in `dat2` will have `NA` in their resulting columns for data from `dat2`.\n\n## [**Right Join**]{style=\"color: #002D62;\"}\n\n`right_join(df1, df2, by)`\n\n```{r}\n#join matching values from df2 to df1 \n```\n\n![](images/right1.jpg){width=\"30%\"}\n\n![](images/right2.jpg){width=\"30%\"}\n\nA right join is a type of database join that combines two data frames based on a common key, similar to a left join but with a focus on retaining all the rows from the right data frame. When performing a right join, all rows from the right data frame are included in the result, and only the matching rows from the left data frame are included. If there is no match, the corresponding columns of the left data frame will be filled with `NA` values\n\n**Example**\n\nContinuing with the previous data,\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Right join \ndf_right <- right_join(dat1, dat2)   \ndf_right\n```\n\nThe right join operation retains all rows from the right data frame (`dat2`) and only those rows from the left data frame (`dat1`) that match based on the specified keys. If there are entries in `dat2` without corresponding matches in `dat1`, the output will show `NA` in place of those unmatched entries from `dat1`\n\n## [**Inner Join**]{style=\"color: #002D62;\"}\n\n`inner_join(df1, df2, by)`\n\n```{r}\n#join values from df2 to df1 and retain only matching rows\n```\n\n![](images/inner1.jpg){width=\"30%\"}\n\n![](images/inner2.jpg){width=\"30%\"}\n\nAn inner join is a type of database join that combines two data frames (or tables) based on a common key or keys, returning only those rows where there is a match in both data frames. In other words, an inner join retrieves the intersection of the two dataset\n\n**Example**\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Inner join \ndf_inner <- inner_join(dat1, dat2)   \ndf_inner\n```\n\nThe resulting data frame (`df_inner`) contains only those rows where there are matching values in the `id` column of both `dat1` and `dat2`\n\n## [**Full join**]{style=\"color: #002D62;\"}\n\n`full_join(df1, df2, by)`\n\n```{r} #join values from df2 to df1 and retain all rows, all values}\n```\n\n![](images/full1.jpg){width=\"30%\"}\n\n![](images/full2.jpg){width=\"30%\"}\n\nA full join (or full outer join) is a type of database join that combines the results of both left and right joins. This means that a full join returns all the rows from both data frames (or tables), regardless of whether there is a match between them. If a row in one data frame does not have a corresponding match in the other, the result will contain `NA` (or missing values) for the columns of the unmatched row from the other data frame.\n\n**Example**\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\n# Full join \ndf_full <- full_join(dat1, dat2)   \ndf_full\n```\n\nThe code `df_full <- full_join(dat1, dat2)` effectively creates a new data frame that combines data from `dat1` and `dat2`, ensuring that all records are retained, either matched or unmatched. This type of join is particularly useful in exploratory data analysis and situations where preserving all relevant data is critical for further analysis and interpretation.\n\n# [**Creating Groups**]{style=\"color: #2C6D26;\"}\n\nData wrangling in R sometimes requires modification or creating a new variable based on certain possible conditions during data analysis.\n\nIt is possible to create new variables with the mutate() function in the tidyverse package.\n\nThe `case_when()` function allows you to vectorize multiple `if_else` statements, i.e. you test condition-1, and then output output-value-1 if the condition-1 is true, then test condition-2, and output output-value-2 if condition-2 is true, the logical statements continue until you specify a value to output if none of the conditions were true.\n\nHowever, if we are interested in creating a new variable within a dataframe based on certain conditions with some `if-elif-else` style logic, then the case_when() function is used with the `mutate()` function, both are in the **tidyverse** package.\n\nTo illustrate the description in the previous slide, let's consider the image below\n\n![](images/case_when.jpg)\n\nThe `TRUE~` is equivalent to the `‘else’` in the `‘if-else’` statement.\n\nIt is important to note that the conditions are evaluated in order, therefore one must proceed from the most specific to the most general condition.\n\nLet’s demonstrate how `case_when` works with these examples using the Australia Soybean 1970 dataset.\n\nWe are going to create four lodging categories such as \\>=1 = 'No Lodging', \\>=1.5 = 'Mild Lodging', \\>=2.5 = 'Moderate Lodging', and \\>=3.5 = 'Heavy Lodging'.\n\n```{r}\n#|echo=TRUE\n\ndat <- read_csv(\"australia.soybean1970.csv\") \ndat\n```\n\n```{r }\n#|echo=TRUE\n#|tidy=FALSE\n\ndat_new <- dat |>      \t\tmutate(         \t\t\tlodging_grp = case_when(                                       lodging >= 3.5 ~ \"Heavy Lodging\",                                 \t\t  lodging >= 2.5 ~ \"Moderate Lodging\",                                \t\t  \tlodging >= 1.5 ~ \"Mild Lodging\",                                 \t\t  lodging >= 1 ~ \"No Lodging\",                                 \t\t \t\t       TRUE ~ \"NA\")  \t\t\t ) \n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_new \n```\n\nAlso, we may be interested in creating a new variable from the existing categorical variable.\n\nLet’s use the new data set `dat_new` to demonstrate this process using `mutate` and `case_when` functions and introduce the `IN` operator `%in%` i.e. We create two lodging categories such that `'No Lodging'` and `'Mild Lodging'` will be `\"No Lodging\"`, and `'Moderate Lodging'` and `'Heavy Lodging'` will be `\"Lodging\"`.\n\n```{r}\n#|echo=TRUE\n#|tidy=FALSE\ndat_new <- dat_new |>           mutate(           lodging_grp2 = case_when(           lodging_grp %in% c(\"Heavy Lodging\",\"Moderate Lodging\")  ~ \"Lodging\",           lodging_grp %in% c(\"No Lodging\", \"Mild Lodging\") ~ \"No Lodging\",                                                     TRUE   ~ \"NA\")   \t\t)\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat_new \n```\n\n# [**Strings**]{style=\"color: #2C6D26;\"}\n\nAs we all know that data comes in different formats, numeric or non-numeric (text/string) data format. Data wrangling of non-numeric data sometimes requires splitting of the cell into multiple individual cells or combining multiple cells into a single cell before analysis.\n\nThere are some functions in the tidyverse package used for this purpose such as `unite()`, `separate()`, and `str_sub()`.\n\n-   `unite()`: collapse cells across several columns into a single column.\n\n-   `separate()`: separate each cell in a column into several columns.\n\n-   `str_sub()`: extract a substring from a character vector.\n\nLet’s use a fictitious data set called **BadData** to demonstrate how these functions work.\n\nThe data set has seven (7) variables: Gen: A combination of location, genotype, and replication, Year: Year of trials, Traits: Measured traits (Trait1 – Trait5)\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat <- read_csv(\"BadData.csv\") \ndat\n```\n\nThe first task will be to create separate variables for location, genotype, and replication from the Gen variable.\n\n```{r}\n#|echo=TRUE\n#|tidy=FALSE\ndat1 <- dat |>    separate(Gen, sep = \"-\", into = c(\"LocGen\", \"Rep\")) |>    mutate(           Location = str_sub(LocGen, 1, 2),           Gen = str_sub(LocGen, 3, 5)  \t ) |>    select(Location, Gen, Rep, Year, Trait1, Trait2, Trait3, Trait4, Trait5)\n```\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat1\n```\n\nAlso, we may be interested in creating a new variable which will be a combination of at least two variables. Suppose we want to create a variable called environment `(Env)` using the data set above by combining the Location and Year together.\n\n```{r}\n#|echo=TRUE\n#|results=\"tiny\"\ndat1 <- dat1 |>          unite(Location, Year, col = \"Env\", sep = \"-\") \ndat1\n```\n\n## [**Exercise**]{style=\"color: #2C6D26;\"}\n\n1.  Import Example-02.csv to R and save it to an object named example02 Display the example02 object filter the data by considering: locations Nambour and RedlandBay genotypes G01, G57, and G58, location Brookstead for the year 1970 location Lawes yield between 2 and 3 inclusive, oil greater than 22\n\n2.  Import **Example-02.csv** to R and save to an object named **example02** Create a new variable called `ENV` by combining the first three letters in `loc` and the last two digit in `year`. Categorize the `yield` values of at least 3 as `\"High\"` and other values as `\"Low\"` into a new variable called `yield_grp`. Select `ENV`, `gen`, `yield`, `yield_grp`, `height`, and `oil` and transform the dataset using appropriate variables as `traits`.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.555","editor":"visual","theme":"cosmo","title":"Data Wrangling","author":[{"name":"<font color=#ff6600><b>Biometrics Unit</b></font>","affiliation":"<font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>"}]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}